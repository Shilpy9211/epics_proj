{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#importing all the needed dependencies\n",
    "import import_ipynb\n",
    "import numpy as np #for matrix calculations\n",
    "import csv\n",
    "import os\n",
    "from keras import layers\n",
    "from keras.layers import Input, Dense,Activation, ZeroPadding2D, Flatten, Conv2D, BatchNormalization\n",
    "from keras.layers import AveragePooling2D, MaxPooling2D, Dropout, GlobalMaxPooling2D, GlobalAveragePooling2D\n",
    "from keras.utils import np_utils, print_summary\n",
    "import pandas as pd #for converting csv into our dataframe\n",
    "from keras.models import Sequential\n",
    "from keras.callbacks import ModelCheckpoint\n",
    "import keras.backend as K"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data=pd.read_csv(r\"C:\\Users\\Lenovo\\Project 1 data.csv\") #reading our csv data\n",
    "dataset=np.array(data) #converting the data into an array\n",
    "np.random.shuffle(dataset) #shuffling the dataset\n",
    "X=dataset #x rows\n",
    "Y=dataset #y columns\n",
    "X=X[:, 0:1024]\n",
    "Y=Y[:, 1024]\n",
    "\n",
    "X_train=X[0:70000, :] #splitting the dataset into training and testing datasets\n",
    "X_train=X_train/255 #normalising train\n",
    "X_test=X[70000:72001, :]\n",
    "X_test=X_test/255 #normalising test\n",
    "\n",
    "#reshaping\n",
    "Y=Y.reshape(Y.shape[0], 1)\n",
    "Y_train=Y[0:70000, :]\n",
    "Y_train=Y_train.T #taking transpose \n",
    "Y_test=Y[70000:72001, :]\n",
    "Y_test=Y_test.T"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"number of training examples=\" + str(X_train.shape[0])) #printing our created dataset's information \n",
    "print(\"number of testing examples=\" + str(X_test.shape[0]))\n",
    "print(\"X_train shape:\" + str(X_train.shape))\n",
    "print(\"Y_train shape:\" + str(Y_train.shape))\n",
    "print(\"X_test shape:\" + str(X_test.shape))\n",
    "print(\"Y_test shape:\" + str(Y_test.shape))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "image_x=32 #image size of 32x32(height and width)\n",
    "image_y=32\n",
    "\n",
    "train_y=np_utils.to_categorical(Y_train) #converting into vectors\n",
    "test_y=np_utils.to_categorical(Y_test)\n",
    "train_y=train_y.reshape(train_y.shape[1], train_y.shape[2])\n",
    "test_y=test_y.reshape(test_y.shape[1], test_y.shape[2])\n",
    "X_train=X_train.reshape(X_train.shape[0], image_x, image_y, 1)\n",
    "X_test=X_test.reshape(X_test.shape[0], image_x, image_y, 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"X_train shape:\" + str(X_train.shape)) #printing the shape of train x and train y\n",
    "print(\"Y_train shape:\" + str(train_y.shape))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#building model\n",
    "def keras_model(image_x, image_y): #function1\n",
    "    num_of_classes=37\n",
    "    model=Sequential()\n",
    "    model.add(Conv2D(filters=32, kernel_size=(5, 5), input_shape=(image_x, image_y, 1), activation='relu'))\n",
    "    model.add(MaxPooling2D(pool_size=(2, 2), strides=(2, 2), padding='same'))\n",
    "    model.add(Conv2D(64, (5, 5), activation='relu'))\n",
    "    model.add(MaxPooling2D(pool_size=(5, 5), strides=(5, 5), padding='same'))\n",
    "    model.add(Flatten()) #flattening vector into a vector\n",
    "    model.add(Dense(num_of_classes, activation='softmax'))\n",
    "    model.compile(loss='categorical_crossentropy', optimizer='adam', metrics=['accuracy'])\n",
    "    filepath=\"devanagari.h5\" #saving model after building\n",
    "    checkpoint1=ModelCheckpoint(filepath, monitor='val_acc', verbose=1, save_best_only=True, mode='max')\n",
    "    callbacks_list=[checkpoint1]\n",
    "    \n",
    "    return model, callbacks_list #returning to the calling variables"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model, callbacks_list=keras_model(image_x, image_y) #calling the function\n",
    "model.fit(X_train, train_y, validation_data=(X_test, test_y), epochs=2, batch_size=64, callbacks=callbacks_list)\n",
    "scores=model.evaluate(X_test, test_y, verbose=0)\n",
    "print(\"CNN error :%.2f%%\" % (100-scores[1]*100)) #printing error\n",
    "print_summary(model) #printing the details of the model\n",
    "model.save('devanagari.h5') #saving the model"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
